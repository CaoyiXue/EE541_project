{"cells":[{"cell_type":"markdown","metadata":{"id":"ceEWydxjyTNB"},"source":["## This file contains : deeper ResNet result based on the \"best\" augmentation approach, including ResNet34 and ResNet50"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14026,"status":"ok","timestamp":1652279884711,"user":{"displayName":"caoyi xue","userId":"04480204175187922115"},"user_tz":420},"id":"cgYnxDNtcu70","outputId":"34deb8f8-214f-442a-8c99-d06981aff7f9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["path = \"/content/drive/MyDrive/EE541_project/\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YH7btZLodCoM"},"outputs":[],"source":["import os\n","import math\n","import time\n","import copy\n","import h5py\n","import glob\n","import numpy as np\n","import torch\n","import torchvision\n","from torchvision import transforms\n","import torch.optim as optim\n","import torch.nn as nn\n","from skimage.util import random_noise\n","from torch.utils.data import random_split, Dataset, DataLoader"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1652279888616,"user":{"displayName":"caoyi xue","userId":"04480204175187922115"},"user_tz":420},"id":"OW0YgCf5c1ha","outputId":"8f749c59-b4a4-4e79-c725-1284f431b04b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training on device cuda.\n"]}],"source":["device = (torch.device('cuda') if torch.cuda.is_available()\n","                  else torch.device('cpu'))\n","print(f\"Training on device {device}.\")\n","\n","data_hdf5_root = os.path.join(path, \"data/asl/data.hdf5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R_xIwOREc_bu"},"outputs":[],"source":["random_seed = 123 # set random seed for reproductivity\n","torch.manual_seed(random_seed)\n","torch.cuda.manual_seed(random_seed)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","np.random.seed(random_seed)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ASOBswFedG5-"},"outputs":[],"source":["class HDF5Dataset(Dataset):\n","    def __init__(self, file_path, name, transform=None):\n","        super().__init__\n","        self.file_path = file_path\n","        self.data_cache = {}\n","        self.transform = transform\n","        self.name = str(name)\n","        self.name_label = str(name) + \"_label\"\n","        self.size = None\n","        with h5py.File(file_path, 'r') as hf:\n","            self.data_cache[self.name] = hf[self.name][:]\n","            self.data_cache[self.name_label] = hf[self.name_label][:]\n","            self.size = len(hf[self.name_label])\n","\n","    def __getitem__(self, index):\n","        img = self.data_cache[self.name][index]\n","        if self.transform:\n","            img = self.transform(img)\n","        else:\n","            img = torch.from_numpy(img)\n","\n","        label = self.data_cache[self.name_label][index]\n","        return img, label\n","\n","    def __len__(self):\n","        return self.size"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ldPAZ0NVdHYD"},"outputs":[],"source":["class gaussian_noise():\n","    def __init__(self, mean, stddev):\n","       self.mean = mean\n","       self.stddev = stddev\n","    def __call__(self, img):\n","       gauss_img = random_noise(img, mode='gaussian', mean=self.mean, var=self.stddev, clip=True)\n","       return torch.tensor(gauss_img, dtype=torch.float32)\n","\n","class salt_pepper_noise():\n","    def __init__(self, amount):\n","      self.amount = amount\n","    def __call__(self, img):\n","       sp_img = random_noise(img, mode='s&p', amount=self.amount)\n","       return torch.tensor(sp_img, dtype=torch.float32)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YneBee5DdNl3"},"outputs":[],"source":["def train_loop(n_epochs, train_loader, val_loader, model, loss_fn, optimizer, model_path):\n","    loss_train_list = []\n","    acc_train_list = []\n","    loss_val_list = []\n","    acc_val_list = []\n","    acc_val_max = 0\n","    n_stop = 0\n","    for epoch in range(1, n_epochs+1):\n","        model.train()\n","        loss_train = 0.0\n","        correct = 0\n","        total = 0\n","        start_time = time.time()\n","        print(f\"Epoch {epoch} Training start:\")\n","        for batch_i, (imgs, labels) in enumerate(train_loader):\n","            imgs, labels = imgs.to(device), labels.to(device)\n","            outputs = model(imgs)\n","\n","            loss = loss_fn(outputs, labels)\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            _, predicted = torch.max(outputs, dim=1)\n","            total += labels.shape[0]\n","            correct += int((predicted == labels).sum())\n","            loss_train += loss.item()\n","            if (batch_i) % 200 == 0:\n","                print ('Epoch {}, Step {}, Loss: {:.4f}'\n","                .format(epoch, batch_i, loss.item()))\n","        \n","        loss_train_list.append(loss_train/len(train_loader))\n","        acc_train_list.append(100 * correct/total)\n","        end_time = time.time()\n","        print('Duration: {:2.2f} minutes, Epoch {}, Training loss {:.4f}, Training accuracy {:2.3f}%'\n","        .format((end_time - start_time)/60 ,epoch,\n","            loss_train/len(train_loader), 100*correct/total))\n","\n","        # validation\n","        loss_val = 0.0\n","        correct = 0\n","        total = 0\n","        with torch.no_grad():\n","            model.eval()\n","            for imgs, labels in val_loader:\n","                imgs, labels = imgs.to(device), labels.to(device)\n","                outputs = model(imgs)\n","                _, predicted = torch.max(outputs, dim=1)\n","                total += labels.shape[0]\n","                correct += int((predicted == labels).sum())\n","                loss = loss_fn(outputs, labels)\n","                loss_val += loss.item()\n","\n","            acc_val = 100*correct/total\n","            loss_val_list.append(loss_val/len(val_loader))#loss per batch\n","            acc_val_list.append(acc_val)\n","            print('Epoch {}, Validation loss {:.4f}, Validation accuracy {:2.3f}%'\n","            .format(epoch, loss_val/len(val_loader), acc_val))\n","        \n","            if acc_val > acc_val_max:\n","                acc_val_max = acc_val\n","                model_scripted = torch.jit.script(model)\n","                model_scripted.save(model_path)\n","                print('Detect Improvement, Save Model')\n","            else:\n","                n_stop += 1\n","    \n","        if(n_stop == 2):\n","            break\n","    return (loss_train_list, acc_train_list, loss_val_list, acc_val_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Uth_EooxkWM2"},"outputs":[],"source":["train_transforms = transforms.Compose([transforms.ToTensor(),\n","                                       transforms.Normalize((0.5190, 0.4993, 0.5141),\n","                                                         (0.2280, 0.2555, 0.2637)),\n","                                       transforms.Resize(224),\n","                                       transforms.RandomHorizontalFlip(p=0.5),\n","                                       transforms.RandomApply(transforms=[gaussian_noise(0, 0.35)], p=0.3),\n","                                       transforms.RandomApply(transforms=[salt_pepper_noise(0.35)], p=0.3),\n","                                       transforms.RandomRotation((0, 10))])\n","\n","test_transforms = transforms.Compose([transforms.ToTensor(),\n","                                    transforms.Normalize((0.5190, 0.4993, 0.5141),\n","                                                         (0.2280, 0.2555, 0.2637)),\n","                                    transforms.Resize(224)])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":392},"executionInfo":{"elapsed":91410,"status":"error","timestamp":1652277979661,"user":{"displayName":"caoyi xue","userId":"04480204175187922115"},"user_tz":420},"id":"YnfnUFXhkY8m","outputId":"9ce5f3c3-81c3-4977-ca15-7b210407fa91"},"outputs":[{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-6aa92f2e72f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHDF5Dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_hdf5_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_transforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHDF5Dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_hdf5_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_transforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-ea013518c0dd>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file_path, name, transform)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_label\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_label\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_label\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, args, new_dtype)\u001b[0m\n\u001b[1;32m    785\u001b[0m         \u001b[0mmspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0mfspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0;31m# Patch up the output for NumPy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["train_dataset = HDF5Dataset(data_hdf5_root, name = \"train\", transform = train_transforms)\n","val_dataset = HDF5Dataset(data_hdf5_root, name = \"val\", transform = test_transforms)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["e7265f976a954b20afb57d5375092748","bb93c71276574439a5cb239d83d5a0a7","85feee35bb814067b8b2487633810979","9c99cbcc8bd74afb91cadf244ccd306e","8a65f0c3fef44a4a950124d03b52fb59","80cf48c37fcd4344bda3df1cb222aee7","c4e5156b3cda412aa38c46c9b622927d","934b843ae8c14701a03b8026bffcfc19","99383774d20a43548bd7544663ac73b2","6d8667c9b39a4392ad274be4fbce04b2","e7d6b8643f2f432f833078ceab93eb9c"]},"executionInfo":{"elapsed":12915,"status":"ok","timestamp":1652277730699,"user":{"displayName":"caoyi xue","userId":"04480204175187922115"},"user_tz":420},"id":"83yPPvRhka8x","outputId":"b352b15d-afe3-4e23-c215-8fcb949ebf35"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e7265f976a954b20afb57d5375092748","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0.00/83.3M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["batch_size = 128\n","n_epochs = 10\n","\n","model = torchvision.models.resnet34(pretrained=True)\n","input_num_fc = model.fc.in_features\n","model.fc = nn.Linear(input_num_fc, 29, bias=True)\n","model = model.to(device=device)\n","\n","optimizer = optim.SGD(model.parameters(), lr = 0.001, momentum=0.9)\n","\n","loss_fn = nn.CrossEntropyLoss()\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Bn_JhyhbA0B"},"outputs":[],"source":["model_path = os.path.join(path, \"data/asl/models/ResNet34.pt\")\n","model.load_state_dict(torch.load(model_path))\n","model = model.to(device)\n","model_scripted = torch.jit.script(model)\n","model_scripted.save(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10359089,"status":"ok","timestamp":1652257754835,"user":{"displayName":"caoyi xue","userId":"04480204175187922115"},"user_tz":420},"id":"ixXQt5oxlL4L","outputId":"27f5b4bb-bf49-4943-f6e4-deb55b3eae9b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1 Training start:\n","Epoch 1, Step 0, Loss: 3.6081\n","Epoch 1, Step 200, Loss: 0.5220\n","Epoch 1, Step 400, Loss: 0.2039\n","Duration: 1.8e+01 minutes, Epoch 1, Training loss 0.8633, Training accuracy 80.685%\n","Epoch 1, Validation loss 0.0554, Validation accuracy 99.471%\n","Detect Improvement\n","Epoch 2 Training start:\n","Epoch 2, Step 0, Loss: 0.1997\n","Epoch 2, Step 200, Loss: 0.0905\n","Epoch 2, Step 400, Loss: 0.0429\n","Duration: 1.8e+01 minutes, Epoch 2, Training loss 0.0917, Training accuracy 97.843%\n","Epoch 2, Validation loss 0.0173, Validation accuracy 99.874%\n","Detect Improvement\n","Epoch 3 Training start:\n","Epoch 3, Step 0, Loss: 0.0482\n","Epoch 3, Step 200, Loss: 0.0747\n","Epoch 3, Step 400, Loss: 0.0591\n","Duration: 1.8e+01 minutes, Epoch 3, Training loss 0.0524, Training accuracy 98.711%\n","Epoch 3, Validation loss 0.0098, Validation accuracy 99.920%\n","Detect Improvement\n","Epoch 4 Training start:\n","Epoch 4, Step 0, Loss: 0.0273\n","Epoch 4, Step 200, Loss: 0.0847\n","Epoch 4, Step 400, Loss: 0.0327\n","Duration: 1.8e+01 minutes, Epoch 4, Training loss 0.0360, Training accuracy 99.096%\n","Epoch 4, Validation loss 0.0069, Validation accuracy 99.943%\n","Detect Improvement\n","Epoch 5 Training start:\n","Epoch 5, Step 0, Loss: 0.0227\n","Epoch 5, Step 200, Loss: 0.0156\n","Epoch 5, Step 400, Loss: 0.0225\n","Duration: 1.8e+01 minutes, Epoch 5, Training loss 0.0274, Training accuracy 99.267%\n","Epoch 5, Validation loss 0.0050, Validation accuracy 99.966%\n","Detect Improvement\n","Epoch 6 Training start:\n","Epoch 6, Step 0, Loss: 0.0150\n","Epoch 6, Step 200, Loss: 0.0398\n","Epoch 6, Step 400, Loss: 0.0260\n","Duration: 1.8e+01 minutes, Epoch 6, Training loss 0.0240, Training accuracy 99.376%\n","Epoch 6, Validation loss 0.0061, Validation accuracy 99.891%\n","Epoch 7 Training start:\n","Epoch 7, Step 0, Loss: 0.0186\n","Epoch 7, Step 200, Loss: 0.0158\n","Epoch 7, Step 400, Loss: 0.0312\n","Duration: 1.8e+01 minutes, Epoch 7, Training loss 0.0196, Training accuracy 99.483%\n","Epoch 7, Validation loss 0.0036, Validation accuracy 99.971%\n","Detect Improvement\n","Epoch 8 Training start:\n","Epoch 8, Step 0, Loss: 0.0035\n","Epoch 8, Step 200, Loss: 0.0046\n","Epoch 8, Step 400, Loss: 0.0038\n","Duration: 1.8e+01 minutes, Epoch 8, Training loss 0.0167, Training accuracy 99.565%\n","Epoch 8, Validation loss 0.0029, Validation accuracy 99.983%\n","Detect Improvement\n","Epoch 9 Training start:\n","Epoch 9, Step 0, Loss: 0.0125\n","Epoch 9, Step 200, Loss: 0.0051\n","Epoch 9, Step 400, Loss: 0.0061\n","Duration: 1.8e+01 minutes, Epoch 9, Training loss 0.0152, Training accuracy 99.593%\n","Epoch 9, Validation loss 0.0026, Validation accuracy 99.971%\n"]}],"source":["model_path = os.path.join(path, \"data/asl/models/ResNet34.pt\")\n","res = train_loop(n_epochs, train_loader, val_loader, model, loss_fn, optimizer, model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XE-Mdo8Yn_A4"},"outputs":[],"source":["batch_size = 128\n","n_epochs = 10\n","\n","model = torchvision.models.resnet50(pretrained=True)\n","input_num_fc = model.fc.in_features\n","model.fc = nn.Linear(input_num_fc, 29, bias=True)\n","model = model.to(device=device)\n","\n","optimizer = optim.SGD(model.parameters(), lr = 0.001, momentum=0.9)\n","\n","loss_fn = nn.CrossEntropyLoss()\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r4dvOWa6bdj6"},"outputs":[],"source":["model_scripted = torch.jit.script(model)\n","model_scripted.save(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10190000,"status":"ok","timestamp":1652267949372,"user":{"displayName":"caoyi xue","userId":"04480204175187922115"},"user_tz":420},"id":"XFO7rk1Jn9F7","outputId":"9f8d8737-cb25-430f-861b-eb665b979ca6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1 Training start:\n","Epoch 1, Step 0, Loss: 3.4764\n","Epoch 1, Step 200, Loss: 0.8332\n","Epoch 1, Step 400, Loss: 0.1469\n","Duration: 2.3e+01 minutes, Epoch 1, Training loss 1.0246, Training accuracy 78.277%\n","Epoch 1, Validation loss 0.0517, Validation accuracy 99.489%\n","Detect Improvement\n","Epoch 2 Training start:\n","Epoch 2, Step 0, Loss: 0.0802\n","Epoch 2, Step 200, Loss: 0.1214\n","Epoch 2, Step 400, Loss: 0.1008\n","Duration: 2.3e+01 minutes, Epoch 2, Training loss 0.0927, Training accuracy 97.871%\n","Epoch 2, Validation loss 0.0156, Validation accuracy 99.891%\n","Detect Improvement\n","Epoch 3 Training start:\n","Epoch 3, Step 0, Loss: 0.0829\n","Epoch 3, Step 200, Loss: 0.0858\n","Epoch 3, Step 400, Loss: 0.0465\n","Duration: 2.3e+01 minutes, Epoch 3, Training loss 0.0502, Training accuracy 98.792%\n","Epoch 3, Validation loss 0.0095, Validation accuracy 99.908%\n","Detect Improvement\n","Epoch 4 Training start:\n","Epoch 4, Step 0, Loss: 0.0576\n","Epoch 4, Step 200, Loss: 0.0108\n","Epoch 4, Step 400, Loss: 0.0382\n","Duration: 2.3e+01 minutes, Epoch 4, Training loss 0.0358, Training accuracy 99.112%\n","Epoch 4, Validation loss 0.0069, Validation accuracy 99.908%\n","Epoch 5 Training start:\n","Epoch 5, Step 0, Loss: 0.0349\n","Epoch 5, Step 200, Loss: 0.0088\n","Epoch 5, Step 400, Loss: 0.0285\n","Duration: 2.3e+01 minutes, Epoch 5, Training loss 0.0271, Training accuracy 99.297%\n","Epoch 5, Validation loss 0.0050, Validation accuracy 99.960%\n","Detect Improvement\n","Epoch 6 Training start:\n","Epoch 6, Step 0, Loss: 0.0507\n","Epoch 6, Step 200, Loss: 0.0366\n","Epoch 6, Step 400, Loss: 0.0088\n","Duration: 2.3e+01 minutes, Epoch 6, Training loss 0.0211, Training accuracy 99.430%\n","Epoch 6, Validation loss 0.0037, Validation accuracy 99.971%\n","Detect Improvement\n","Epoch 7 Training start:\n","Epoch 7, Step 0, Loss: 0.0170\n","Epoch 7, Step 200, Loss: 0.0227\n","Epoch 7, Step 400, Loss: 0.0204\n","Duration: 2.3e+01 minutes, Epoch 7, Training loss 0.0171, Training accuracy 99.562%\n","Epoch 7, Validation loss 0.0031, Validation accuracy 99.966%\n"]}],"source":["model_path = os.path.join(path, \"data/asl/models/ResNet50.pt\")\n","res = train_loop(n_epochs, train_loader, val_loader, model, loss_fn, optimizer, model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s6RoVOegkvAi"},"outputs":[],"source":["def test_loop(test_loader, model, loss_fn):\n","    loss_total = 0.0\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        model.eval()\n","        for imgs, labels in test_loader:\n","            imgs, labels = imgs.to(device), labels.to(device)\n","            outputs = model(imgs)\n","            _, predicted = torch.max(outputs, dim=1)\n","            total += labels.shape[0]\n","            correct += int((predicted == labels).sum())\n","            loss = loss_fn(outputs, labels)\n","            loss_total += loss.item()\n","\n","        acc_test = 100*correct/total\n","    print('Total loss {:.4f}, Total accuracy {:2.3f}%'\n","            .format(loss_total/len(test_loader), acc_test))\n","    return acc_test, correct, predicted, total\n","\n","def accuracy_test(test_loader, test2_loader, model, loss_fn):\n","  print(\"Test Data:\")\n","  acc_test, cn, predict, total_num= test_loop(test_loader, model, loss_fn)\n","  print(f\"accuracy : {acc_test :2.3f}, correct number : {cn}/{total_num}\")\n","  print(\"Test2 Data:\")\n","  acc_test2, cn2, predict2, total_num2= test_loop(test2_loader, model, loss_fn)\n","  print(f\"accuracy : {acc_test2 :2.3f}, correct number : {cn2}/{total_num2}\")\n","\n","  return (acc_test, cn, acc_test2, cn2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QTi2ytAtkxgu"},"outputs":[],"source":["test_dataset = HDF5Dataset(data_hdf5_root, name=\"test\", transform = test_transforms)\n","test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n","test2_dataset = HDF5Dataset(data_hdf5_root, name=\"test2\", transform = test_transforms)\n","test2_loader = DataLoader(test2_dataset, batch_size=len(test2_dataset), shuffle=False)\n","\n","loss_fn = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":20030,"status":"error","timestamp":1652279951118,"user":{"displayName":"caoyi xue","userId":"04480204175187922115"},"user_tz":420},"id":"CIGTHqhKkzO3","outputId":"61355050-8164-4b66-f413-16320c51315e"},"outputs":[{"name":"stdout","output_type":"stream","text":["ResNet18 :\n","Test Data:\n","Total loss 0.0051, Total accuracy 100.000%\n","accuracy : 100.000, correct number : 29/29\n","Test2 Data:\n","Total loss 3.1547, Total accuracy 24.074%\n","accuracy : 24.074, correct number : 416/1728\n","---------------------------------\n","ResNet34 :\n","Test Data:\n","Total loss 0.0013, Total accuracy 100.000%\n","accuracy : 100.000, correct number : 29/29\n","Test2 Data:\n","Total loss 2.7954, Total accuracy 28.241%\n","accuracy : 28.241, correct number : 488/1728\n","---------------------------------\n","ResNet50 :\n","Test Data:\n","Total loss 0.0021, Total accuracy 100.000%\n","accuracy : 100.000, correct number : 29/29\n","Test2 Data:\n"]},{"ename":"RuntimeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-a9ed577ca7b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest2_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-b2267137d1fd>\u001b[0m in \u001b[0;36maccuracy_test\u001b[0;34m(test_loader, test2_loader, model, loss_fn)\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"accuracy : {acc_test :2.3f}, correct number : {cn}/{total_num}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test2 Data:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m   \u001b[0macc_test2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcn2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_num2\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtest_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest2_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"accuracy : {acc_test2 :2.3f}, correct number : {cn2}/{total_num2}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-b2267137d1fd>\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(test_loader, model, loss_fn)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript, serialized code (most recent call last):\n  File \"code/__torch__/torchvision/models/resnet/___torch_mangle_59.py\", line 22, in forward\n  def forward(self: __torch__.torchvision.models.resnet.___torch_mangle_59.ResNet,\n    x: Tensor) -> Tensor:\n    return (self)._forward_impl(x, )\n            ~~~~~~~~~~~~~~~~~~~ <--- HERE\n  def _forward_impl(self: __torch__.torchvision.models.resnet.___torch_mangle_59.ResNet,\n    x: Tensor) -> Tensor:\n  File \"code/__torch__/torchvision/models/resnet/___torch_mangle_59.py\", line 34, in _forward_impl\n    x3 = (maxpool).forward(x2, )\n    layer1 = self.layer1\n    x4 = (layer1).forward(x3, )\n          ~~~~~~~~~~~~~~~ <--- HERE\n    layer2 = self.layer2\n    x5 = (layer2).forward(x4, )\n  File \"code/__torch__/torch/nn/modules/container/___torch_mangle_30.py\", line 14, in forward\n    _1 = getattr(self, \"1\")\n    _2 = getattr(self, \"2\")\n    input0 = (_0).forward(input, )\n              ~~~~~~~~~~~ <--- HERE\n    input1 = (_1).forward(input0, )\n    return (_2).forward(input1, )\n  File \"code/__torch__/torchvision/models/resnet.py\", line 32, in forward\n    out5 = (conv3).forward(out4, )\n    bn3 = self.bn3\n    out6 = (bn3).forward(out5, )\n            ~~~~~~~~~~~~ <--- HERE\n    downsample = self.downsample\n    identity = (downsample).forward(x, )\n  File \"code/__torch__/torch/nn/modules/batchnorm/___torch_mangle_10.py\", line 35, in forward\n    weight = self.weight\n    bias = self.bias\n    _3 = _0(input, running_mean, running_var, weight, bias, bn_training, 0.10000000000000001, 1.0000000000000001e-05, )\n         ~~ <--- HERE\n    return _3\n  def _check_input_dim(self: __torch__.torch.nn.modules.batchnorm.___torch_mangle_10.BatchNorm2d,\n  File \"code/__torch__/torch/nn/functional.py\", line 14, in batch_norm\n  else:\n    pass\n  _2 = torch.batch_norm(input, weight, bias, running_mean, running_var, training, momentum, eps, True)\n       ~~~~~~~~~~~~~~~~ <--- HERE\n  return _2\ndef relu(input: Tensor,\n\nTraceback of TorchScript, original code (most recent call last):\n  File \"/usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py\", line 283, in forward\n    def forward(self, x: Tensor) -> Tensor:\n        return self._forward_impl(x)\n               ~~~~~~~~~~~~~~~~~~ <--- HERE\n  File \"/usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py\", line 271, in _forward_impl\n        x = self.maxpool(x)\n    \n        x = self.layer1(x)\n            ~~~~~~~~~~~ <--- HERE\n        x = self.layer2(x)\n        x = self.layer3(x)\n  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\", line 141, in forward\n    def forward(self, input):\n        for module in self:\n            input = module(input)\n                    ~~~~~~ <--- HERE\n        return input\n  File \"/usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py\", line 153, in forward\n    \n        out = self.conv3(out)\n        out = self.bn3(out)\n              ~~~~~~~~ <--- HERE\n    \n        if self.downsample is not None:\n  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/batchnorm.py\", line 168, in forward\n        used for normalization (i.e. in eval mode when buffers are not None).\n        \"\"\"\n        return F.batch_norm(\n               ~~~~~~~~~~~~ <--- HERE\n            input,\n            # If buffers are not to be tracked, ensure that they won't be updated\n  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\", line 2421, in batch_norm\n        _verify_batch_size(input.size())\n\n    return torch.batch_norm(\n           ~~~~~~~~~~~~~~~~ <--- HERE\n        input, weight, bias, running_mean, running_var, training, momentum, eps, torch.backends.cudnn.enabled\n    )\nRuntimeError: CUDA out of memory. Tried to allocate 5.17 GiB (GPU 0; 14.76 GiB total capacity; 7.52 GiB already allocated; 2.02 GiB free; 11.49 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"]}],"source":["models_root = os.path.join(path, \"data/asl/models/\")\n","for f in glob.glob(os.path.join(models_root, '*.pt')):\n","    print(f.split(\"/\")[-1].split(\".\")[0], \":\")\n","    model = torch.jit.load(f)\n","    model = model.to(device)\n","    _ = accuracy_test(test_loader, test2_loader, model, loss_fn)\n","    print(\"---------------------------------\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S8N1b-WqboKS"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNZdV2Atadb+ugtY1lX+zAs","machine_shape":"hm","name":"DeeperResNet.ipynb","provenance":[]},"interpreter":{"hash":"e9975367b6d99bb8e806cecfcaee5b098ac617bd15dda647f2b708a9e5c2f2c6"},"kernelspec":{"display_name":"Python 3.8.12 ('ee541')","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.12"},"widgets":{"application/vnd.jupyter.widget-state+json":{"6d8667c9b39a4392ad274be4fbce04b2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80cf48c37fcd4344bda3df1cb222aee7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85feee35bb814067b8b2487633810979":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_934b843ae8c14701a03b8026bffcfc19","max":87319819,"min":0,"orientation":"horizontal","style":"IPY_MODEL_99383774d20a43548bd7544663ac73b2","value":87319819}},"8a65f0c3fef44a4a950124d03b52fb59":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"934b843ae8c14701a03b8026bffcfc19":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99383774d20a43548bd7544663ac73b2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9c99cbcc8bd74afb91cadf244ccd306e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d8667c9b39a4392ad274be4fbce04b2","placeholder":"​","style":"IPY_MODEL_e7d6b8643f2f432f833078ceab93eb9c","value":" 83.3M/83.3M [00:01&lt;00:00, 150MB/s]"}},"bb93c71276574439a5cb239d83d5a0a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_80cf48c37fcd4344bda3df1cb222aee7","placeholder":"​","style":"IPY_MODEL_c4e5156b3cda412aa38c46c9b622927d","value":"100%"}},"c4e5156b3cda412aa38c46c9b622927d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e7265f976a954b20afb57d5375092748":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bb93c71276574439a5cb239d83d5a0a7","IPY_MODEL_85feee35bb814067b8b2487633810979","IPY_MODEL_9c99cbcc8bd74afb91cadf244ccd306e"],"layout":"IPY_MODEL_8a65f0c3fef44a4a950124d03b52fb59"}},"e7d6b8643f2f432f833078ceab93eb9c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
