{"cells":[{"cell_type":"markdown","metadata":{"id":"ArcmeTX86DRY"},"source":["#### This file contains : get an output video showing ASL classification results from our model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive/', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["path = \"./\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZESQm0Dcnr8A"},"outputs":[],"source":["import torch\n","import numpy as np\n","import cv2\n","from torchvision.transforms import transforms   \n","from PIL import Image\n","from glob import glob\n","import math\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12572,"status":"ok","timestamp":1652240452710,"user":{"displayName":"caoyi xue","userId":"04480204175187922115"},"user_tz":420},"id":"aD4aZwjQw1fs","outputId":"a27599d2-a5b8-409a-d120-fb204bb0ab3c"},"outputs":[],"source":["device = (torch.device('cuda') if torch.cuda.is_available()\n","                  else torch.device('cpu'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":105992,"status":"ok","timestamp":1652242574042,"user":{"displayName":"caoyi xue","userId":"04480204175187922115"},"user_tz":420},"id":"rOEQTACixooA","outputId":"a4a94ab5-90a5-4242-a95d-43aa39fe151a"},"outputs":[],"source":["def eval_video(model, transform, videoFile, datasetclasses):\n","    videodir,videoFname = os.path.dirname(videoFile), os.path.basename(videoFile)\n","    tempdir = os.path.join(videodir,'temp')\n","    if not os.path.isdir(tempdir):\n","        os.makedirs(tempdir)\n","        print(\"created folder : \", tempdir)\n","    else:\n","        files = glob(tempdir+'/*')\n","        print('Clearing folder : ', tempdir)\n","        for f in files:\n","            os.remove(f)\n","    preddir = os.path.join(videodir,'pred')\n","    if not os.path.isdir(preddir):\n","        os.makedirs(preddir)\n","        print(\"created folder : \", preddir)\n","    else:\n","        files = glob(preddir+'/*')\n","        print('Clearing folder : ', preddir)\n","        for f in files:\n","            os.remove(f)\n","    \n","    cap = cv2.VideoCapture(videoFile)\n","    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","    frameRate = cap.get(5)\n","    outfrateratio=10\n","    frame_width = int(cap.get(3))\n","    frame_height = int(cap.get(4))\n","    print(frame_width,frame_height)\n","    \n","    count = 0\n","    while(cap.isOpened()):\n","        frameId = cap.get(1)\n","        ret, frame = cap.read()\n","        if (frameId % math.floor(outfrateratio) == 0):\n","            framename = \"_frame%d.jpg\"%count\n","            count+=1\n","            framepath = os.path.join(tempdir,framename)\n","            cv2.imwrite(framepath, frame)\n","            \n","            img = Image.open(framepath)\n","            img_tensor = transform(img).to(device).unsqueeze(0)\n","            model.eval()\n","            output = model(img_tensor)\n","            _, index = torch.max(output, 1)\n","            index = index.cpu()\n","            prediction = datasetclasses[index]\n","            if prediction != 'nothing':\n","                cv2.putText(frame, prediction, (20, 500), cv2.FONT_HERSHEY_SIMPLEX, 8, (0, 200, 0), 40)\n","            \n","            predframepath = os.path.join(preddir,framename)\n","            cv2.imwrite(predframepath, frame)\n","        if(frameId == frame_count):\n","            break\n","    cap.release()\n","    return frameRate, frame_width, frame_height, preddir\n","\n","def get_outmp4(videoFile, output_dir, model_path, test_transforms, classes):\n","    \n","    model = torch.jit.load(model_path)\n","    model = model.to(device)\n","    model_name = model_path.split('/')[-1].split('.')[0]\n","    output_name = model_name + 'out.mp4'\n","\n","    frameRate,frame_width,frame_height,preddir = eval_video(model, test_transforms, videoFile, classes)\n","\n","    output_path = os.path.join(output_dir, output_name)\n","    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'MP4V'), frameRate, (frame_width,frame_height))\n","    img_array=[]\n","    for file in os.listdir(preddir):\n","        path = preddir+'/'+file\n","        img = cv2.imread(path)\n","        img_array.append(img)\n","    for i in range(len(img_array)):\n","        out.write(img_array[i])\n","\n","    out.release()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["videoFile = os.path.join(path, \"data/asl/test_video/Cropped_Video.mp4\")\n","output_dir = os.path.join(path, \"data/asl/test_video/\")\n","classes = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', \n","        'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', \n","        'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\n","test_transforms = transforms.Compose([transforms.ToTensor(),\n","                                transforms.Normalize((0.5190, 0.4993, 0.5141),\n","                                                        (0.2280, 0.2555, 0.2637)),\n","                                transforms.Resize(224)])\n","                                \n","models_root = os.path.join(path, \"data/asl/models/\")\n","for f in glob(os.path.join(models_root, '*.pt')):\n","        print(f)\n","        get_outmp4(videoFile, output_dir, f, test_transforms, classes)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"name":"VideoTest.ipynb","provenance":[]},"interpreter":{"hash":"e9975367b6d99bb8e806cecfcaee5b098ac617bd15dda647f2b708a9e5c2f2c6"},"kernelspec":{"display_name":"Python 3.8.12 ('ee541')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"}},"nbformat":4,"nbformat_minor":0}
