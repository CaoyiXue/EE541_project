{"cells":[{"cell_type":"markdown","metadata":{"id":"aVaeUhl2s1TJ"},"source":["## This file contains: use ResNet18 to find the \"best\" augmentation method. And get the accuracy results including No augmentation, augmentation1, augmentation2, augmentation3, augmentation4"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16873,"status":"ok","timestamp":1652281992742,"user":{"displayName":"caoyi xue","userId":"04480204175187922115"},"user_tz":420},"id":"V3W0ME1Q-XNN","outputId":"2669a9ff-cb14-412d-cd5e-98b2dcb78397"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["path = \"/content/drive/MyDrive/EE541_project/\""]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":2696,"status":"ok","timestamp":1652281995436,"user":{"displayName":"caoyi xue","userId":"04480204175187922115"},"user_tz":420},"id":"MGW0EDi_-RCV"},"outputs":[],"source":["import os\n","import math\n","import glob\n","import time\n","import copy\n","import h5py\n","import numpy as np\n","import torch\n","import torchvision\n","from torchvision import transforms\n","import torch.optim as optim\n","import torch.nn as nn\n","from skimage.util import random_noise\n","from torch.utils.data import random_split, Dataset, DataLoader"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1652281995785,"user":{"displayName":"caoyi xue","userId":"04480204175187922115"},"user_tz":420},"id":"01J7y5Mo_pnh","outputId":"c5f1f3cc-67b3-447e-d93c-7cadbbc1a90a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training on device cuda.\n"]}],"source":["device = (torch.device('cuda') if torch.cuda.is_available()\n","                  else torch.device('cpu'))\n","print(f\"Training on device {device}.\")\n","\n","data_hdf5_root = os.path.join(path, \"data/asl/data.hdf5\")"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1652281995785,"user":{"displayName":"caoyi xue","userId":"04480204175187922115"},"user_tz":420},"id":"_hUZIp2J_byB"},"outputs":[],"source":["random_seed = 123 # set random seed for reproductivity\n","torch.manual_seed(random_seed)\n","torch.cuda.manual_seed(random_seed)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","np.random.seed(random_seed)"]},{"cell_type":"markdown","metadata":{"id":"9DWc64KpUfKU"},"source":["#### HDF5Dataset Class and Augmentation Noise"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1652281995786,"user":{"displayName":"caoyi xue","userId":"04480204175187922115"},"user_tz":420},"id":"0xSiM4rk-FLk"},"outputs":[],"source":["class HDF5Dataset(Dataset):\n","    def __init__(self, file_path, name, transform=None):\n","        super().__init__\n","        self.file_path = file_path\n","        self.data_cache = {}\n","        self.transform = transform\n","        self.name = str(name)\n","        self.name_label = str(name) + \"_label\"\n","        self.size = None\n","        with h5py.File(file_path, 'r') as hf:\n","            self.data_cache[self.name] = hf[self.name][:]\n","            self.data_cache[self.name_label] = hf[self.name_label][:]\n","            self.size = len(hf[self.name_label])\n","\n","    def __getitem__(self, index):\n","        img = self.data_cache[self.name][index]\n","        if self.transform:\n","            img = self.transform(img)\n","        else:\n","            img = torch.from_numpy(img)\n","\n","        label = self.data_cache[self.name_label][index]\n","        return img, label\n","\n","    def __len__(self):\n","        return self.size"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1652281995786,"user":{"displayName":"caoyi xue","userId":"04480204175187922115"},"user_tz":420},"id":"w4jgJNWGAF1b"},"outputs":[],"source":["class gaussian_noise():\n","    def __init__(self, mean, stddev):\n","       self.mean = mean\n","       self.stddev = stddev\n","    def __call__(self, img):\n","       gauss_img = random_noise(img, mode='gaussian', mean=self.mean, var=self.stddev, clip=True)\n","       return torch.tensor(gauss_img, dtype=torch.float32)\n","       \n","class salt_pepper_noise():\n","    def __init__(self, amount):\n","      self.amount = amount\n","    def __call__(self, img):\n","       sp_img = random_noise(img, mode='s&p', amount=self.amount)\n","       return torch.tensor(sp_img, dtype=torch.float32)"]},{"cell_type":"markdown","metadata":{"id":"5mXpCaLBeumy"},"source":["#### Training loop"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S4PDhvghAvC4"},"outputs":[],"source":["def train_loop(n_epochs, train_loader, val_loader, model, loss_fn, optimizer, model_path):\n","    loss_train_list = []\n","    acc_train_list = []\n","    loss_val_list = []\n","    acc_val_list = []\n","    acc_val_max = 0\n","    n_stop = 0\n","    for epoch in range(1, n_epochs+1):\n","        model.train()\n","        loss_train = 0.0\n","        correct = 0\n","        total = 0\n","        start_time = time.time()\n","        print(f\"Epoch {epoch} Training start:\")\n","        for batch_i, (imgs, labels) in enumerate(train_loader):\n","            imgs, labels = imgs.to(device), labels.to(device)\n","            outputs = model(imgs)\n","\n","            loss = loss_fn(outputs, labels)\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            _, predicted = torch.max(outputs, dim=1)\n","            total += labels.shape[0]\n","            correct += int((predicted == labels).sum())\n","            loss_train += loss.item()\n","            if (batch_i) % 200 == 0:\n","                print ('Epoch {}, Step {}, Loss: {:.4f}'\n","                .format(epoch, batch_i, loss.item()))\n","                #torch.save(model.state_dict(), path_store_net)\n","        \n","        loss_train_list.append(loss_train/len(train_loader))\n","        acc_train_list.append(100 * correct/total)\n","        end_time = time.time()\n","        print('Duration: {:2.2f} minutes, Epoch {}, Training loss {:.4f}, Training accuracy {:2.3f}%'\n","        .format((end_time - start_time)/60 ,epoch,\n","            loss_train/len(train_loader), 100*correct/total))\n","\n","        # validation\n","        loss_val = 0.0\n","        correct = 0\n","        total = 0\n","        with torch.no_grad():\n","            model.eval()\n","            for imgs, labels in val_loader:\n","                imgs, labels = imgs.to(device), labels.to(device)\n","                outputs = model(imgs)\n","                _, predicted = torch.max(outputs, dim=1)\n","                total += labels.shape[0]\n","                correct += int((predicted == labels).sum())\n","                loss = loss_fn(outputs, labels)\n","                loss_val += loss.item()\n","\n","            acc_val = 100*correct/total\n","            loss_val_list.append(loss_val/len(val_loader))#loss per batch\n","            acc_val_list.append(acc_val)\n","            print('Epoch {}, Validation loss {:.4f}, Validation accuracy {:2.3f}%'\n","            .format(epoch, loss_val/len(val_loader), acc_val))\n","        \n","            if acc_val > acc_val_max:\n","                acc_val_max = acc_val\n","                model_scripted = torch.jit.script(model)\n","                model_scripted.save(model_path)\n","                print('Detect Improvement, Save Model')\n","            else:\n","                n_stop += 1\n","    \n","        if(n_stop == 2):\n","            break\n","    return (loss_train_list, acc_train_list, loss_val_list, acc_val_list)"]},{"cell_type":"markdown","metadata":{"id":"DIOF6LVReS95"},"source":["#### The 1st augmentation"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1652281996907,"user":{"displayName":"caoyi xue","userId":"04480204175187922115"},"user_tz":420},"id":"8XPxvNHSH8uV"},"outputs":[],"source":["train_transforms = transforms.Compose([transforms.ToTensor(),\n","                                       transforms.Normalize((0.5190, 0.4993, 0.5141),\n","                                                            (0.2280, 0.2555, 0.2637)),\n","                                       transforms.Resize(224),\n","                                       transforms.RandomHorizontalFlip(p=0.5),\n","                                       transforms.RandomApply(transforms=[gaussian_noise(0.1, 0.3)], p=0.3),\n","                                       transforms.RandomApply(transforms=[salt_pepper_noise(0.3)], p=0.3),\n","                                       transforms.RandomRotation((0, 5))])\n","\n","test_transforms = transforms.Compose([transforms.ToTensor(),\n","                                    transforms.Normalize((0.5190, 0.4993, 0.5141),\n","                                                         (0.2280, 0.2555, 0.2637)),\n","                                    transforms.Resize(224)])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KfTLyIlHAF1d"},"outputs":[],"source":["train_dataset = HDF5Dataset(data_hdf5_root, name = \"train\", transform = train_transforms)\n","val_dataset = HDF5Dataset(data_hdf5_root, name = \"val\", transform = test_transforms)\n","\n","print(f\"train size is {len(train_dataset)}\")\n","print(f\"validation size is {len(val_dataset)}\")\n","print(f\"All data size is {len(train_dataset)+len(val_dataset)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q9znceD4AFVm"},"outputs":[],"source":["batch_size = 128\n","n_epochs = 10\n","\n","model = torchvision.models.resnet18(pretrained=True)\n","input_num_fc = model.fc.in_features\n","model.fc = nn.Linear(input_num_fc, 29, bias=True)\n","model = model.to(device=device)\n","\n","optimizer = optim.SGD(model.parameters(), lr = 0.001, momentum=0.9)\n","\n","loss_fn = nn.CrossEntropyLoss()\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n","\n","model_path = os.path.join(path, \"data/asl/aug_models/ResNet18_aug1.pt\")\n","res = train_loop(n_epochs, train_loader, val_loader, model, loss_fn, optimizer, model_path)"]},{"cell_type":"markdown","metadata":{"id":"RDVkT1DN01cb"},"source":["#### The 2nd Augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3plOqsoa00nM"},"outputs":[],"source":["train_transforms = transforms.Compose([transforms.ToTensor(),\n","                                       transforms.Normalize((0.5190, 0.4993, 0.5141),\n","                                                         (0.2280, 0.2555, 0.2637)),\n","                                       transforms.Resize(224),\n","                                       transforms.RandomHorizontalFlip(p=0.5),\n","                                       transforms.RandomApply(transforms=[gaussian_noise(0, 0.35)], p=0.3),\n","                                       transforms.RandomApply(transforms=[salt_pepper_noise(0.35)], p=0.3),\n","                                       transforms.RandomRotation((0, 10))])\n","\n","train_dataset = HDF5Dataset(data_hdf5_root, name = \"train\", transform = train_transforms)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WHX8hpzm2yJL"},"outputs":[],"source":["batch_size = 128\n","n_epochs = 10\n","\n","model = torchvision.models.resnet18(pretrained=True)\n","input_num_fc = model.fc.in_features\n","model.fc = nn.Linear(input_num_fc, 29, bias=True)\n","model = model.to(device=device)\n","\n","optimizer = optim.SGD(model.parameters(), lr = 0.001, momentum=0.9)\n","\n","loss_fn = nn.CrossEntropyLoss()\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n","\n","model_path = os.path.join(path, \"data/asl/aug_models/ResNet18_aug2.pt\")\n","res = train_loop(n_epochs, train_loader, val_loader, model, loss_fn, optimizer, model_path)"]},{"cell_type":"markdown","metadata":{"id":"sWWvlxuIF_zC"},"source":["#### The 3rd Augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QpNtz24jGDsW"},"outputs":[],"source":["train_transforms = transforms.Compose([transforms.ToTensor(),\n","                                       transforms.Normalize((0.5190, 0.4993, 0.5141),\n","                                                         (0.2280, 0.2555, 0.2637)),\n","                                       transforms.Resize(224),\n","                                       transforms.RandomHorizontalFlip(p=0.5),\n","                                       transforms.RandomApply(transforms=[gaussian_noise(0, 0.35)], p=0.3),\n","                                       transforms.RandomApply(transforms=[salt_pepper_noise(0.35)], p=0.3),\n","                                       transforms.RandomRotation((0, 10)),\n","                                       transforms.RandomGrayscale(0.1)])\n","\n","train_dataset = HDF5Dataset(data_hdf5_root, name = \"train\", transform = train_transforms)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ql-62uivKTzC"},"outputs":[],"source":["batch_size = 128\n","n_epochs = 10\n","\n","model = torchvision.models.resnet18(pretrained=True)\n","input_num_fc = model.fc.in_features\n","model.fc = nn.Linear(input_num_fc, 29, bias=True)\n","model = model.to(device=device)\n","\n","optimizer = optim.SGD(model.parameters(), lr = 0.001, momentum=0.9)\n","\n","loss_fn = nn.CrossEntropyLoss()\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n","model_path = os.path.join(path, \"data/asl/aug_models/ResNet18_aug3.pt\")\n","res = train_loop(n_epochs, train_loader, val_loader, model, loss_fn, optimizer, model_path)"]},{"cell_type":"markdown","metadata":{"id":"eVzgbslJGbF6"},"source":["#### The 4th augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g0RWU8d8HcFB"},"outputs":[],"source":["train_transforms = transforms.Compose([transforms.ToTensor(),\n","                                       transforms.Normalize((0.5190, 0.4993, 0.5141),\n","                                                         (0.2280, 0.2555, 0.2637)),\n","                                       transforms.Resize(224),\n","                                       transforms.RandomHorizontalFlip(p=0.5),\n","                                       transforms.RandomApply(transforms=[gaussian_noise(0.1, 0.2)], p=0.3),\n","                                       transforms.RandomApply(transforms=[salt_pepper_noise(0.2)], p=0.3),\n","                                       transforms.RandomRotation((0, 5))])\n","\n","train_dataset = HDF5Dataset(data_hdf5_root, name = \"train\", transform = train_transforms)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oxQKZmOeGiJo"},"outputs":[],"source":["batch_size = 128\n","n_epochs = 10\n","\n","model = torchvision.models.resnet18(pretrained=True)\n","input_num_fc = model.fc.in_features\n","model.fc = nn.Linear(input_num_fc, 29, bias=True)\n","model = model.to(device=device)\n","\n","optimizer = optim.SGD(model.parameters(), lr = 0.001, momentum=0.9)\n","\n","loss_fn = nn.CrossEntropyLoss()\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n","model_path = os.path.join(path, \"data/asl/aug_models/ResNet18_aug4.pt\")\n","res = train_loop(n_epochs, train_loader, val_loader, model, loss_fn, optimizer, model_path)"]},{"cell_type":"markdown","metadata":{"id":"5iXMC4Kwan42"},"source":["#### Training without augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QYsVaPe3aqrH"},"outputs":[],"source":["train_dataset = HDF5Dataset(data_hdf5_root, name = \"train\", transform = test_transforms)\n","# validation dataset is same"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iL25PI9DbAxS"},"outputs":[],"source":["batch_size = 128\n","n_epochs = 10\n","\n","model = torchvision.models.resnet18(pretrained=True)\n","input_num_fc = model.fc.in_features\n","model.fc = nn.Linear(input_num_fc, 29, bias=True)\n","model = model.to(device=device)\n","\n","optimizer = optim.SGD(model.parameters(), lr = 0.001, momentum=0.9)\n","\n","loss_fn = nn.CrossEntropyLoss()\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n","\n","model_path = os.path.join(path, \"data/asl/aug_models/ResNet18_noaug.pt\")\n","res = train_loop(n_epochs, train_loader, val_loader, model, loss_fn, optimizer, model_path)"]},{"cell_type":"markdown","metadata":{"id":"Ovzqt-EIBwFL"},"source":["#### Test!"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1652282000737,"user":{"displayName":"caoyi xue","userId":"04480204175187922115"},"user_tz":420},"id":"QN0nbjFGByp5"},"outputs":[],"source":["def test_loop(test_loader, model, loss_fn):\n","    loss_total = 0.0\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        model.eval()\n","        for imgs, labels in test_loader:\n","            imgs, labels = imgs.to(device), labels.to(device)\n","            outputs = model(imgs)\n","            _, predicted = torch.max(outputs, dim=1)\n","            total += labels.shape[0]\n","            correct += int((predicted == labels).sum())\n","            loss = loss_fn(outputs, labels)\n","            loss_total += loss.item()\n","\n","        acc_test = 100*correct/total\n","    print('Total loss {:.4f}, Total accuracy {:2.3f}%'\n","            .format(loss_total/len(test_loader), acc_test))\n","    return acc_test, correct, predicted, total\n","\n","def accuracy_test(test_loader, test2_loader, model, loss_fn):\n","  print(\"Test Data:\")\n","  acc_test, cn, predict, total_num= test_loop(test_loader, model, loss_fn)\n","  print(f\"accuracy : {acc_test :2.3f}, correct number : {cn}/{total_num}\")\n","  print(\"Test2 Data:\")\n","  acc_test2, cn2, predict2, total_num2= test_loop(test2_loader, model, loss_fn)\n","  print(f\"accuracy : {acc_test2 :2.3f}, correct number : {cn2}/{total_num2}\")\n","\n","  return (acc_test, cn, acc_test2, cn2)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":1563,"status":"ok","timestamp":1652282005859,"user":{"displayName":"caoyi xue","userId":"04480204175187922115"},"user_tz":420},"id":"gS-rz42aQP2u"},"outputs":[],"source":["test_dataset = HDF5Dataset(data_hdf5_root, name=\"test\", transform = test_transforms)\n","test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n","test2_dataset = HDF5Dataset(data_hdf5_root, name=\"test2\", transform = test_transforms)\n","test2_loader = DataLoader(test2_dataset, batch_size=len(test2_dataset), shuffle=False)\n","\n","loss_fn = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19573,"status":"ok","timestamp":1652282207741,"user":{"displayName":"caoyi xue","userId":"04480204175187922115"},"user_tz":420},"id":"BgCRtQYEnSiR","outputId":"d64ca360-7c7c-4b5e-cf7c-b78ab36c7bf1"},"outputs":[{"name":"stdout","output_type":"stream","text":["ResNet18_aug1 :\n","Test Data:\n","Total loss 0.0053, Total accuracy 100.000%\n","accuracy : 100.000, correct number : 29/29\n","Test2 Data:\n","Total loss 3.1349, Total accuracy 24.016%\n","accuracy : 24.016, correct number : 415/1728\n","---------------------------------\n","ResNet18_noaug :\n","Test Data:\n","Total loss 0.0069, Total accuracy 100.000%\n","accuracy : 100.000, correct number : 29/29\n","Test2 Data:\n","Total loss 3.3366, Total accuracy 15.799%\n","accuracy : 15.799, correct number : 273/1728\n","---------------------------------\n","ResNet18_aug3 :\n","Test Data:\n","Total loss 0.0036, Total accuracy 100.000%\n","accuracy : 100.000, correct number : 29/29\n","Test2 Data:\n","Total loss 3.3422, Total accuracy 23.553%\n","accuracy : 23.553, correct number : 407/1728\n","---------------------------------\n","ResNet18_aug4 :\n","Test Data:\n","Total loss 0.0057, Total accuracy 100.000%\n","accuracy : 100.000, correct number : 29/29\n","Test2 Data:\n","Total loss 3.0620, Total accuracy 23.553%\n","accuracy : 23.553, correct number : 407/1728\n","---------------------------------\n","ResNet18_aug2 :\n","Test Data:\n","Total loss 0.0051, Total accuracy 100.000%\n","accuracy : 100.000, correct number : 29/29\n","Test2 Data:\n","Total loss 3.1547, Total accuracy 24.074%\n","accuracy : 24.074, correct number : 416/1728\n","---------------------------------\n"]}],"source":["models_root = os.path.join(path, \"data/asl/aug_models/\")\n","for f in glob.glob(os.path.join(models_root, '*.pt')):\n","    print(f.split(\"/\")[-1].split(\".\")[0], \":\")\n","    model = torch.jit.load(f)\n","    model = model.to(device)\n","    _ = accuracy_test(test_loader, test2_loader, model, loss_fn)\n","    print(\"---------------------------------\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c4W0rUQahc3g"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"ResNet18.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"}},"nbformat":4,"nbformat_minor":0}
